{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\VENV\\api_prediction\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "from src.data_processor import RawDataProcessor\n",
    "from src.problem_config import create_prob_config\n",
    "from src.drift_detector import ks_drift_detect\n",
    "prob_config = create_prob_config(\"phase-3\", \"prob-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "\n",
    "def log_model_to_tracker(model, metrics, desc):\n",
    "    MLFLOW_TRACKING_URI = 'http://192.168.88.113:5000'\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(\"phase-3_prob-2_lgbm\")\n",
    "    MLFLOW_MODEL_PREFIX = \"model\"\n",
    "    mlflow.start_run(description=desc)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_params(model.get_params())\n",
    "    signature = infer_signature(test_x.astype(np.float64), predictions)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=MLFLOW_MODEL_PREFIX,\n",
    "        signature=signature,\n",
    "        pip_requirements ='src/requirements.txt'\n",
    "        #registered_model_name=\"phase-1_prob-1_model-1\"\n",
    "    )\n",
    "\n",
    "    experimentid = mlflow.active_run().info.run_id\n",
    "    mlflow.end_run()\n",
    "    return experimentid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import xtran and ytrain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "training_data = pd.read_parquet(prob_config.raw_data_path)\n",
    "training_data = training_data.drop_duplicates()\n",
    "\n",
    "training_data, category_index = RawDataProcessor.build_category_features(\n",
    "            training_data, prob_config.categorical_cols\n",
    "        )\n",
    "\n",
    "with open(prob_config.category_index_path, \"wb\") as f:\n",
    "    pickle.dump(category_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_labels = training_data[training_data.duplicated(prob_config.feature_cols, keep=False)].sort_values(by=prob_config.feature_cols)\n",
    "conflict_labels[\"org_idx\"] = conflict_labels.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conflict = conflict_labels.groupby(prob_config.feature_cols).agg({\"org_idx\": lambda x: tuple(x), \"label\": lambda x: tuple(x)}).reset_index()\n",
    "#apply(lambda x: tuple(x.index)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data.drop_duplicates(subset=prob_config.feature_cols, keep=False, inplace=True)\n",
    "target_col = prob_config.target_col\n",
    "train_x0 = training_data.drop([target_col], axis=1)\n",
    "train_y0 = training_data[[target_col]]\n",
    "\n",
    "train, dev = train_test_split(training_data, test_size=0.1, random_state=123)\n",
    "\n",
    "train_x = train.drop([\"label\"], axis=1)\n",
    "train_y = train[[target_col]]\n",
    "test_x = dev.drop([\"label\"], axis=1)\n",
    "test_y = dev[[target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "labels_unq = train_y0['label'].unique()\n",
    "labels_unq.sort()\n",
    "for i in range(len(labels_unq)):\n",
    "    labels_dict[labels_unq[i]] = i\n",
    "\n",
    "inv_labels_dict = {v: k for k, v in labels_dict.items()}\n",
    "model_classes_path = prob_config.data_path / 'classes.npy'\n",
    "np.save(model_classes_path, labels_unq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softmax', predictor=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "eval_set = [(train_x, train_y), (test_x, test_y)]\n",
    "model0 = LGBMClassifier(objective=\"multiclass\", random_state=123, boosting_type='dart')\n",
    "model0.fit(train_x0, train_y0, verbose=False)#, eval_set=eval_set)\n",
    "modelxgb = XGBClassifier(objective=\"multi:softmax\")\n",
    "modelxgb.fit(train_x0, train_y0.replace(labels_dict), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lightgbm as lgb\n",
    "\n",
    "#lgb.plot_metric(model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softmax', predictor=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_labels = data_conflict['label']\n",
    "proba_fix = pd.DataFrame(model0.predict_proba(data_conflict[prob_config.feature_cols]), columns=list(model0.classes_))\n",
    "fix_label = []\n",
    "for i in range(len(conflict_labels)):\n",
    "     labels = conflict_labels[i]\n",
    "     fix_label.append(labels[proba_fix[list(labels)].iloc[i].argmax()])\n",
    "\n",
    "fix_label = pd.DataFrame(fix_label)\n",
    "\n",
    "train_x_new = pd.DataFrame(np.concatenate((train_x0, data_conflict[prob_config.feature_cols])), columns=train_x.columns)\n",
    "train_y_new = pd.DataFrame(np.concatenate((train_y0, fix_label)), columns=train_y.columns)\n",
    "\n",
    "model1 = XGBClassifier(objective=\"multi:softmax\")\n",
    "\n",
    "# model1 = LGBMClassifier(objective=\"binary\", random_state=123, is_unbalance=True)\n",
    "model1.fit(train_x_new, train_y_new.replace(labels_dict), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics: {'accuracy_score': 0.9298744769874477}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model1.predict(test_x)\n",
    "#predictions = s.predict_model(best[0], data = test_x)[\"prediction_label\"]\n",
    "accuracy = accuracy_score(predictions, test_y.replace(labels_dict))\n",
    "metrics = {\"accuracy_score\": accuracy}\n",
    "print(f\"metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data22 = pd.read_parquet('data/phase-2/prob-2/raw_train.parquet')\n",
    "\n",
    "data22 = RawDataProcessor.apply_category_features(\n",
    "    raw_df=data22,\n",
    "    categorical_cols=prob_config.categorical_cols,\n",
    "    category_index=category_index,\n",
    ")\n",
    "\n",
    "data22.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_idx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(18610, 61207)</td>\n",
       "      <td>(Exploits, Denial of Service)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(16762, 25916, 46019)</td>\n",
       "      <td>(Denial of Service, Exploits, Information Gath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10701, 59138, 59472)</td>\n",
       "      <td>(Exploits, Information Gathering, Denial of Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(32122, 43251, 57080)</td>\n",
       "      <td>(Information Gathering, Denial of Service, Exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4625, 12609, 23488, 40864)</td>\n",
       "      <td>(Malware, Denial of Service, Exploits, Informa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>(2052, 12187, 56610)</td>\n",
       "      <td>(Denial of Service, Exploits, Information Gath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>(13656, 37184, 50897)</td>\n",
       "      <td>(Exploits, Information Gathering, Denial of Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>(6358, 11822, 55169)</td>\n",
       "      <td>(Exploits, Denial of Service, Information Gath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>(2594, 12669)</td>\n",
       "      <td>(Exploits, Denial of Service)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>(35586, 48668)</td>\n",
       "      <td>(Exploits, Denial of Service)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1664 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          org_idx  \\\n",
       "0                  (18610, 61207)   \n",
       "1           (16762, 25916, 46019)   \n",
       "2           (10701, 59138, 59472)   \n",
       "3           (32122, 43251, 57080)   \n",
       "4     (4625, 12609, 23488, 40864)   \n",
       "...                           ...   \n",
       "1659         (2052, 12187, 56610)   \n",
       "1660        (13656, 37184, 50897)   \n",
       "1661         (6358, 11822, 55169)   \n",
       "1662                (2594, 12669)   \n",
       "1663               (35586, 48668)   \n",
       "\n",
       "                                                  label  \n",
       "0                         (Exploits, Denial of Service)  \n",
       "1     (Denial of Service, Exploits, Information Gath...  \n",
       "2     (Exploits, Information Gathering, Denial of Se...  \n",
       "3     (Information Gathering, Denial of Service, Exp...  \n",
       "4     (Malware, Denial of Service, Exploits, Informa...  \n",
       "...                                                 ...  \n",
       "1659  (Denial of Service, Exploits, Information Gath...  \n",
       "1660  (Exploits, Information Gathering, Denial of Se...  \n",
       "1661  (Exploits, Denial of Service, Information Gath...  \n",
       "1662                      (Exploits, Denial of Service)  \n",
       "1663                      (Exploits, Denial of Service)  \n",
       "\n",
       "[1664 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_labels2 = data22[data22.duplicated(prob_config.feature_cols, keep=False)].sort_values(by=prob_config.feature_cols)\n",
    "conflict_labels2[\"org_idx\"] = conflict_labels2.index\n",
    "conflict_labels2.groupby(prob_config.feature_cols).agg({\"org_idx\": lambda x: tuple(x), \"label\": lambda x: tuple(x)}).reset_index()[[\"org_idx\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(is_unbalance=True, objective=&#x27;binary&#x27;, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, objective=&#x27;binary&#x27;, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, objective='binary', random_state=123)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data22.drop_duplicates(subset=prob_config.feature_cols, keep=False, inplace=True)\n",
    "\n",
    "train_x_new = pd.DataFrame(np.concatenate((train_x0, data22[prob_config.feature_cols])), columns=train_x.columns)\n",
    "train_y_new = pd.DataFrame(np.concatenate((train_y0, data22[[prob_config.target_col]])), columns=train_y.columns)\n",
    "\n",
    "model2 = LGBMClassifier(objective=\"binary\", random_state=123, is_unbalance=True)\n",
    "model2.fit(train_x_new, train_y_new, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888353252318302"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data22.drop_duplicates(subset=prob_config.feature_cols, keep=False, inplace=True)\n",
    "accuracy_score(model0.predict(training_data.drop([target_col], axis=1)), training_data[[target_col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.1 ms ± 1.11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "modelxgb.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lleaves\n",
    "model_path = \".venv/phase2_2_lgbm.txt\"\n",
    "model0.booster_.save_model(filename=model_path)\n",
    "llvm_model = lleaves.Model(model_file=model_path)\n",
    "llvm_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ms ± 360 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "z = llvm_model.predict(test_x)\n",
    "labels = np.argmax(z, axis=1)\n",
    "classes = model0.classes_\n",
    "labels = [classes[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6301be2cdcfe47afb14da2424e8c124b'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_description = \"\"\"\n",
    "### Header\n",
    "LGBM model, First Base Model Prob2\n",
    "Model: LGBM\n",
    "    \"\"\"\n",
    "log_model_to_tracker_lgbm(model2, metrics, run_description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save referent for drift detection.\n",
    "X_baseline = train_x0.sample(1000)\n",
    "X_baseline_df = pd.DataFrame(X_baseline, columns=prob_config.drift_cols)\n",
    "X_baseline_df.to_parquet(prob_config.driff_ref_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import redis\n",
    "import pickle\n",
    "# Load data for problem 1\n",
    "rc2 = redis.Redis(host='localhost', db=2, port=6379)\n",
    "\n",
    "captured_x = pd.DataFrame()\n",
    "for key in rc2.keys():\n",
    "    captured_data = pickle.loads(rc2.get(key))\n",
    "    captured_x = pd.concat([captured_x, captured_data])\n",
    "\n",
    "#captured_x.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "#captured_x = apply_category_features(\n",
    "#    raw_df=captured_x[train_x0.columns],\n",
    "#    categorical_cols=prob_config.categorical_cols,\n",
    "#    category_index=category_index,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature37</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature29</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature35</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.315934</td>\n",
       "      <td>INT</td>\n",
       "      <td>4.256000e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.492686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>372.107265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4667.444206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.004091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.209288</td>\n",
       "      <td>2.639593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8866.796943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.273952</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1.008715e+04</td>\n",
       "      <td>5.650000e+02</td>\n",
       "      <td>0.313822</td>\n",
       "      <td>255.0</td>\n",
       "      <td>http</td>\n",
       "      <td>3924.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240390</td>\n",
       "      <td>316.660025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7763.113809</td>\n",
       "      <td>5326.917090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.638178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.093191</td>\n",
       "      <td>3.214469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.661908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.687166</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1.422364e+06</td>\n",
       "      <td>6.610000e+02</td>\n",
       "      <td>1.575556</td>\n",
       "      <td>255.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>-439.369067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.196987</td>\n",
       "      <td>5439.471865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.989293</td>\n",
       "      <td>2.879847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.859722</td>\n",
       "      <td>INT</td>\n",
       "      <td>8.400000e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.590194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-122.402656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1532.726454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.390149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.509609</td>\n",
       "      <td>3.899141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.013076</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.250888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-567.023876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2081.799772</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.181647</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.613624</td>\n",
       "      <td>3.695266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.315604</td>\n",
       "      <td>INT</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>6.658514e-09</td>\n",
       "      <td>0.782214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>308.238249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>900.130696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.494361</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.602370</td>\n",
       "      <td>4.515803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.264351</td>\n",
       "      <td>INT</td>\n",
       "      <td>2.000000e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.332541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>98.219524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6944.998493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.404023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.146412</td>\n",
       "      <td>3.123270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6673.116690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.366335</td>\n",
       "      <td>FIN</td>\n",
       "      <td>3.358990e+03</td>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>0.475187</td>\n",
       "      <td>255.0</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112239</td>\n",
       "      <td>-59.633238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.124297</td>\n",
       "      <td>5069.522457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.763291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.138606</td>\n",
       "      <td>3.416183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6540.847392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.006549</td>\n",
       "      <td>FIN</td>\n",
       "      <td>4.984898e+03</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>0.290594</td>\n",
       "      <td>255.0</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.092901</td>\n",
       "      <td>25.613197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345.025125</td>\n",
       "      <td>-2638.345765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.429945</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.443458</td>\n",
       "      <td>2.831593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.295122</td>\n",
       "      <td>INT</td>\n",
       "      <td>1.140000e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.419896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-592.832031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3332.999788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.001823</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.772422</td>\n",
       "      <td>4.735647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42816 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature17  feature37  feature6 feature4     feature11     feature27  \\\n",
       "0       0.000000        0.0 -2.315934      INT  4.256000e+08  0.000000e+00   \n",
       "1    8866.796943        0.0 -3.273952      FIN  1.008715e+04  5.650000e+02   \n",
       "2      18.661908        0.0 -3.687166      FIN  1.422364e+06  6.610000e+02   \n",
       "3       0.000000        0.0 -1.859722      INT  8.400000e+07  0.000000e+00   \n",
       "4       0.000000        0.0 -7.013076      INT  0.000000e+00  0.000000e+00   \n",
       "..           ...        ...       ...      ...           ...           ...   \n",
       "995     0.000000        0.0 -2.315604      INT  1.000000e+08  6.658514e-09   \n",
       "996     0.000000        0.0 -4.264351      INT  2.000000e+08  0.000000e+00   \n",
       "997  6673.116690        0.0 -6.366335      FIN  3.358990e+03  7.100000e+01   \n",
       "998  6540.847392        0.0 -6.006549      FIN  4.984898e+03  4.500000e+01   \n",
       "999     0.000000        0.0 -6.295122      INT  1.140000e+08  0.000000e+00   \n",
       "\n",
       "     feature34  feature22 feature3  feature29  ...  feature1   feature15  \\\n",
       "0     0.492686        0.0        -        0.0  ...  0.000010  372.107265   \n",
       "1     0.313822      255.0     http     3924.0  ...  1.240390  316.660025   \n",
       "2     1.575556      255.0        -        0.0  ...  0.016294 -439.369067   \n",
       "3     0.590194        0.0        -        0.0  ...  0.000008 -122.402656   \n",
       "4     0.250888        0.0        -        0.0  ...  0.000000 -567.023876   \n",
       "..         ...        ...      ...        ...  ...       ...         ...   \n",
       "995   0.782214        0.0        -        0.0  ...  0.000008  308.238249   \n",
       "996   1.332541        0.0        -        0.0  ...  0.000004   98.219524   \n",
       "997   0.475187      255.0      dns        0.0  ...  1.112239  -59.633238   \n",
       "998   0.290594      255.0        -        0.0  ...  1.092901   25.613197   \n",
       "999   1.419896        0.0      dns        0.0  ...  0.000004 -592.832031   \n",
       "\n",
       "     feature28    feature18     feature8  feature41  feature35  feature31  \\\n",
       "0          0.0     0.000000  4667.444206        0.0  -2.004091        2.0   \n",
       "1          1.0  7763.113809  5326.917090        0.0   3.638178        0.0   \n",
       "2          0.0    18.196987  5439.471865        0.0   0.023476        0.0   \n",
       "3          0.0     0.000000 -1532.726454        0.0  -7.390149        2.0   \n",
       "4          0.0     0.000000  2081.799772        1.0 -11.181647        2.0   \n",
       "..         ...          ...          ...        ...        ...        ...   \n",
       "995        0.0     0.000000   900.130696        0.0  -8.494361        2.0   \n",
       "996        0.0     0.000000  6944.998493        0.0   2.404023        2.0   \n",
       "997        0.0   251.124297  5069.522457        0.0   3.763291        1.0   \n",
       "998        0.0   345.025125 -2638.345765        0.0  -3.429945        1.0   \n",
       "999        0.0     0.000000  3332.999788        0.0  -2.001823        2.0   \n",
       "\n",
       "     feature10  feature39  \n",
       "0    68.209288   2.639593  \n",
       "1    53.093191   3.214469  \n",
       "2    76.989293   2.879847  \n",
       "3    84.509609   3.899141  \n",
       "4    58.613624   3.695266  \n",
       "..         ...        ...  \n",
       "995  37.602370   4.515803  \n",
       "996  47.146412   3.123270  \n",
       "997  44.138606   3.416183  \n",
       "998  36.443458   2.831593  \n",
       "999  27.772422   4.735647  \n",
       "\n",
       "[42816 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captured_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc2.flushdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rc2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_captured_x = captured_x.copy() #drop([\"is_drift\", \"batch_id\"], axis=1)\n",
    "np_captured_x = np_captured_x.astype(train_x.dtypes.to_dict())\n",
    "np_captured_x['label'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allkey = rc2.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
