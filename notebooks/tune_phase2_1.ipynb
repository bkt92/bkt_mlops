{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\VENV\\api_prediction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\VENV\\\\api_prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')\n",
    "from src.data_processor import RawDataProcessor\n",
    "from src.problem_config import create_prob_config \n",
    "prob_config = create_prob_config(\"phase-2\", \"prob-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "\n",
    "def log_model_to_tracker_lgbm(model, metrics, desc):\n",
    "    MLFLOW_TRACKING_URI = 'http://192.168.88.113:5000'\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(\"phase-2_prob-1_lgbm\")\n",
    "    MLFLOW_MODEL_PREFIX = \"model\"\n",
    "    mlflow.start_run(description=desc)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_params(model.get_params())\n",
    "    signature = infer_signature(test_x.astype(np.float64), predictions)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=MLFLOW_MODEL_PREFIX,\n",
    "        signature=signature,\n",
    "        pip_requirements ='src/requirements.txt'\n",
    "        #registered_model_name=\"phase-1_prob-1_model-1\"\n",
    "    )\n",
    "\n",
    "    experimentid = mlflow.active_run().info.run_id\n",
    "    mlflow.end_run()\n",
    "    return experimentid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "training_data = pd.read_parquet(prob_config.raw_data_path)\n",
    "\n",
    "training_data, category_index = RawDataProcessor.build_category_features(\n",
    "            training_data, prob_config.categorical_cols\n",
    "        )\n",
    "\n",
    "target_col = prob_config.target_col\n",
    "train_x = training_data.drop([target_col], axis=1)\n",
    "train_y = training_data[[target_col]]\n",
    "\n",
    "# Store the category_index\n",
    "with open(prob_config.category_index_path, \"wb\") as f:\n",
    "    pickle.dump(category_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(objective=&#x27;binary&#x27;, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(objective=&#x27;binary&#x27;, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(objective='binary', random_state=123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model0 = LGBMClassifier(objective=\"binary\", random_state=123)\n",
    "model0.fit(train_x, train_y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = training_data.sample(1000)\n",
    "\n",
    "test_x = sample.drop([target_col], axis=1)\n",
    "test_y = sample[[target_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics: {'test_auc': 0.991104987330875}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "predictions = model0.predict_proba(test_x.astype(np.float64))[:,1]\n",
    "#predictions = d4p.gbt_classification_prediction(nClasses=2).compute(test_x, daal_model)\n",
    "#predictions = llvm_model.predict(test_x)\n",
    "auc_score = roc_auc_score(test_y, predictions)\n",
    "metrics = {\"test_auc\": auc_score}\n",
    "print(f\"metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.6 ms ± 4.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "gbm.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lleaves\n",
    "model_path = prob_config.data_path / \"phase2_1_lgbm.txt\"\n",
    "llvm_model_path = prob_config.data_path / \"phase2_1_lleaves\"\n",
    "model0.booster_.save_model(filename=model_path)\n",
    "llvm_model = lleaves.Model(model_file=model_path)\n",
    "llvm_model.compile(cache=llvm_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.8 ms ± 555 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "llvm_model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "daal_model = d4p.get_gbt_model_from_lightgbm(model0.booster_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.48 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "daal_prediction = d4p.gbt_classification_prediction(nClasses=2, resultsToEvaluate=\"computeClassLabels|computeClassProbabilities\").compute(test_x, daal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\n",
    "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm  # noqa\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import numpy\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_registered_converter(\n",
    "    LGBMClassifier, 'LightGbmLGBMClassifier',\n",
    "    calculate_linear_classifier_output_shapes, convert_lightgbm,\n",
    "    options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_onnx = convert_sklearn(\n",
    "    model0, 'pipeline_lightgbm',\n",
    "    [('input', FloatTensorType([None, 41]))],\n",
    "    target_opset={'': 12, 'ai.onnx.ml': 2})\n",
    "\n",
    "# And save.\n",
    "with open(\"pipeline_lightgbm.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict [1 1 1 1 0]\n",
      "predict_proba [[0.17720758 0.82279242]]\n"
     ]
    }
   ],
   "source": [
    "print(\"predict\", model0.predict(test_x.to_numpy()[:5].astype(numpy.float32)))\n",
    "print(\"predict_proba\", model0.predict_proba(test_x.to_numpy()[:1].astype(numpy.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict [1 1 1 1 0]\n",
      "predict_proba [{0: 0.17720752954483032, 1: 0.8227924704551697}]\n"
     ]
    }
   ],
   "source": [
    "sess = rt.InferenceSession(\"pipeline_lightgbm.onnx\")\n",
    "\n",
    "pred_onx = sess.run(None, {\"input\": test_x.to_numpy()[:5].astype(numpy.float32)})\n",
    "print(\"predict\", pred_onx[0])\n",
    "print(\"predict_proba\", pred_onx[1][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92 ms ± 111 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pred_onx = sess.run(None, {\"input\": test_x.to_numpy().astype(numpy.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/06 17:04:13 INFO mlflow.tracking.fluent: Experiment with name 'phase-2_prob-1_lgbm' does not exist. Creating a new experiment.\n",
      "c:\\VENV\\api_prediction\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'061becc8f54344c19f02d1c70b5e8271'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_description = \"\"\"\n",
    "### Header\n",
    "LGBM model, First Base Model Prob1\n",
    "Model: LGBM\n",
    "    \"\"\"\n",
    "log_model_to_tracker_lgbm(model0, metrics, run_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/04 15:33:48 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - numpy (current: 1.23.0, required: numpy==1.23.5)\n",
      " - pyarrow (current: 6.0.1, required: pyarrow==11.0.0)\n",
      " - pandas (current: 1.5.3, required: pandas==2.0.1)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pathlib\n",
    "MLFLOW_TRACKING_URI = 'http://localhost:5000'\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "model_uri = str(pathlib.Path(\"models:/\", \"phase-2_prob-1_model\", \"2\").as_posix())\n",
    "model0_ref = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99900175e-01, 9.98248478e-05],\n",
       "       [1.28688555e-02, 9.87131144e-01],\n",
       "       [7.01833056e-04, 9.99298167e-01],\n",
       "       ...,\n",
       "       [1.12157821e-03, 9.98878422e-01],\n",
       "       [9.03452717e-05, 9.99909655e-01],\n",
       "       [9.99874004e-01, 1.25996093e-04]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0_ref._model_impl.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlflow.lightgbm._LGBModelWrapper at 0x1c60c4bc2e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0_ref._model_impl.lgb_model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old KS Drift from alibi_detect\n",
    "from alibi_detect.cd import KSDrift\n",
    "X_baseline = train_x.sample(100)\n",
    "cd = KSDrift(p_val=0.05, x_ref=X_baseline.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_x.sample(1000).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.6 ms ± 372 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cd.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save referent for drift detection.\n",
    "#X_baseline_df = pd.DataFrame(X_baseline, columns=prob_config.drift_cols)\n",
    "#X_baseline_df.to_parquet(prob_config.driff_ref_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import joblib\n",
    "\n",
    "# N là số lượng cluster\n",
    "N = 19000 * len(np.unique(train_y))\n",
    "# Train clustering model cho data đã có label\n",
    "#kmeans = MiniBatchKMeans(n_clusters=N, random_state=0, n_init='auto').fit(train_x)\n",
    "\n",
    "#joblib.dump(kmeans, 'data/captured_data/phase-1/prob-1/kmeans.cpk')\n",
    "kmeans = joblib.load('data/captured_data/phase-1/prob-1/kmeans.cpk')\n",
    "\n",
    "# Tạo 1 mảng ánh xạ cluster với 1 label mới (do các data drift thuộc cùng 1 cluster sẽ có label giống nhau)\n",
    "new_labels = []\n",
    "\n",
    "# Duyệt từng cluster\n",
    "for  i  in  range(N):\n",
    "\t# Lấy các label của các data point thuộc cluster i\n",
    "\tmask = (kmeans.labels_ == i)\n",
    "\tcluster_labels = train_y[mask]\n",
    "\n",
    "\tif  len(cluster_labels) == 0:\n",
    "\t\t# Nếu cluster i rỗng thì xác định cluster i ánh xạ với 1 label mặc định (ở đây lựa chọn là 0)\n",
    "\t\tnew_labels.append(0)\n",
    "\telse:\n",
    "\t\t# Tìm label mới cho cả cụm cluster trong trường hợp cụm cluster khác rỗng\n",
    "\t\t#if  isinstance(train_y.flatten()[0], float):\n",
    "\t\t\t# Nếu là bài toán Regression thì lấy giá trị trung bình của các label thuộc cluster\n",
    "\t\t#\tnew_labels.append(np.mean(cluster_labels.flatten()))\n",
    "\t\t#else:\n",
    "\t\t\t# Nếu là bài toán Classification thì lấy label xuất hiện nhiều nhất trong cluster\n",
    "\t\t\tnew_labels.append(np.bincount(cluster_labels.to_numpy().flatten()).argmax())\n",
    "\n",
    "# Ánh xạ lại label cho data drift dựa trên kết quả predict cluster ở trên\n",
    "y_drift_propagated = [new_labels[c] for  c  in  kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_auc': 0.8626996177558589}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_drift_test_propagated = [ new_labels[c] for c in kmeans.predict(train_x)]\n",
    "propagated_auc = {\"test_auc\": roc_auc_score(train_y, y_drift_propagated)}\n",
    "propagated_auc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import redis\n",
    "import pickle\n",
    "# Load data for problem 1\n",
    "rc1 = redis.Redis(host='localhost', db=1, port=6379,  socket_keepalive=True)\n",
    "\n",
    "captured_x = pd.DataFrame()\n",
    "for key in rc1.keys():\n",
    "    captured_data = pickle.loads(rc1.get(key))\n",
    "    captured_x = pd.concat([captured_x, captured_data])\n",
    "\n",
    "#captured_x.drop_duplicates(inplace=True, ignore_index=True)\n",
    "#captured_x = apply_category_features(\n",
    "#    raw_df=captured_x[train_x.columns],\n",
    "#    categorical_cols=prob_config.categorical_cols,\n",
    "#    category_index=category_index,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "allkey = rc1.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"123\", \"predictions\": [0.17184121780284572, 0.5953986713502124, 0.0001133657096940821, 0.9992450288983301, 0.9998837423846397, 0.0003030946270267483, 0.9996831122319352, 0.23541836157519033, 0.9988011570355567, 0.998847434582315, 0.37096931743029105, 0.00010753247802201693, 0.9919733628931873, 0.9908676570528765, 0.8843435571298845, 0.9660647124988747, 0.9961278444571551, 0.44205564084248294, 0.9998914116782995, 0.9988057968653068, 0.9520427435892356, 0.7488336134943746, 0.9998553174685054, 0.6131201365037977, 0.6784925091272985, 0.9998837423846397, 0.0003030946270267483, 0.9542313913421884, 8.112650766885705e-05, 0.9996761344458595, 0.00014380166010169007, 0.00015151533312950143, 0.9972517226388409, 0.9996763701451702, 0.9998976521337084, 0.23363852127166262, 0.9883603621430732, 9.99543225157526e-05, 0.9970358422087782, 0.004055404603537885, 0.00010376334014242447, 0.00015770480692099383, 0.9989234039513359, 0.0036083983894646164, 0.9855891833629019, 7.463308964851023e-05, 0.9998837423846397, 0.000150676564379467, 0.00035219129353964264, 0.999882156940931, 0.9998837423846397, 0.0001589307182692447, 0.9988591035950506, 0.999326822359848, 0.9998837423846397, 0.00011314146764485965, 0.0001348695244536368, 0.9986021740567926, 0.999338630255691, 0.22616172144003127, 0.2891830346433974, 0.9998837423846397, 8.731009098676141e-05, 0.0001634943783215461, 0.992032634022698, 0.7646147577829424, 0.9991061106332605, 0.9575980027378947, 0.36622394318703927, 0.9895819925310675, 0.9980431804801976, 0.40296310484895376, 0.18848305583249458, 0.923655278071983, 0.37395211641484705, 0.9994757355145081, 0.9993004920730504, 0.9846933006176631, 0.9981978620333753, 0.9917356969439712, 0.9998756145055341, 0.99896226000624, 0.45051302785585473, 0.9919733628931873, 9.043567186112572e-05, 0.9970415443531114, 0.9948315371018684, 0.00011039751457047962, 0.999905894469594, 0.00015151533312950143, 0.9945288908263871, 0.998719341553204, 8.832393716367365e-05, 0.9919278732807512, 0.5684098838237261, 0.0001235460814705884, 0.9923699054063052, 0.999905894469594, 0.00011365732641982459, 0.0001235460814705884, 0.9916679072819811, 0.4685471188174404, 0.998847434582315, 0.9830593084227371, 0.005639395540872238, 0.004709454405617328, 0.2334070681234599, 0.999611156961625, 0.9976579881340498, 0.9998837423846397, 8.259157335431933e-05, 0.8716633967898968, 0.9937178849548317, 0.6195826809546777, 0.9720128208195741, 0.9998837423846397, 9.904180434869662e-05, 0.9998837423846397, 0.008450688890804607, 0.9998837423846397, 0.9916814642969751, 0.9998837423846397, 0.00014556443123628037, 0.0001753944800659037, 0.00016751696417021178, 0.999611156961625, 0.9998837423846397, 9.019768304404032e-05, 0.9996805919320815, 0.8254059953320588, 0.9236862358896006, 7.458245169351344e-05, 0.9886194105165876, 0.00013763272252902568, 0.00017059688022057445, 0.999326822359848, 0.9970111664613435, 0.9993150424692666, 0.9427129369500078, 0.00014525239591547695, 0.9815831212575993, 0.9218026988200921, 0.2136950162868121, 0.1566190919561913, 0.9996808243884079, 0.00016660886658768304, 0.589065673682908, 0.9994240091443302, 0.999905894469594, 0.999905894469594, 0.9999171540317326, 0.00011553976814189034, 0.999905894469594, 0.5341543329601256, 0.5599896034246395, 0.9908786927656156, 0.00018871746505163555, 0.999611156961625, 0.9824418186583822, 0.9851721187544437, 0.9891097496546859, 0.00012202139865220661, 0.9991421174222261, 0.9872929065830971, 0.9993150424692666, 0.9994688678098297, 0.5991116510119086, 0.00011145263973631303, 0.9917356969439712, 0.9982117950482199, 0.00012940135755089608, 0.9998837423846397, 0.00015151533312950143, 0.9975527886304196, 0.9669110637373957, 0.17393057590947666, 0.994480773711547, 0.9998832554840715, 0.9998837423846397, 0.0054348320895737795, 0.997623116954531, 0.9998832554840715, 0.9965475425981877, 0.9992981669439214, 0.9921129214537399, 0.5169388098976042, 0.0001733167532024423, 0.9853798864005165, 0.3621751816598531, 0.8657522232833271, 0.9989140453371481, 0.9998837423846397, 0.9701891581379642, 0.9998837423846397, 0.9274259532210714, 0.7883417165646646, 0.9990459633370216, 0.7597366714961706, 0.9998837423846397, 0.9996057308606813, 0.8080966838648429, 0.9998837423846397, 0.9999096547282988, 0.17059129536205106, 0.999905894469594, 0.7863034038077028, 0.26090949789616286, 0.9873998961661734, 0.9998837423846397, 0.9867887943795125, 0.5474018842132248, 0.3872463022709639, 0.999656348207354, 0.00015151533312950143, 0.9996786899063498, 0.9970085772761249, 0.9918268653600526, 0.9983089485449057, 0.9996828965823179, 0.9991533466765844, 0.9998971169824639, 0.9998837423846397, 0.19229661436085613, 0.9999137089777405, 0.9979696104316953, 0.9576963592784232, 0.0001426913179768187, 0.6122700893660501, 8.345739958908247e-05, 0.5591496919797673, 0.4531923945131454, 7.463308964851023e-05, 0.00015151533312950143, 0.00015239623684520963, 0.4106493393135533, 0.19378685225026349, 0.00010229156250077507, 0.4302281122930627, 0.00012249565741572909, 0.00015151533312950143, 0.00012587051393735563, 0.6018529819958853, 0.00015151533312950143, 0.999905894469594, 0.00015151533312950143, 0.0001259960932658382, 0.994719771358296, 0.9996761344458595, 0.988758894886612, 9.789528569541941e-05, 0.031376277843444475, 0.9959274793900382, 0.9996828965823179, 0.33393018365136096, 0.999611156961625, 0.00014069073863939423, 0.5678285158154632, 0.00012722595267356822, 0.41648539091379355, 0.00017947071903221844, 0.00014967490737515443, 0.9994688678098297, 0.9983482490756066, 0.9998899512983547, 6.500185083784603e-05, 0.9994723541621012, 0.9969746589956775, 0.0001685133262242585, 0.9998837423846397, 0.00011623343978666357, 0.00013615017190342937, 0.00012940135755089608, 0.0001485512376990111, 0.9998832554840715, 0.00012664843694041187, 0.998870094397896, 0.23505169429768902, 0.999905894469594, 0.9996805919320815, 0.9998399404915767, 0.21288417565744355, 0.9998837423846397, 0.00012249565741572909, 0.44521750360841805, 0.00011145263973631303, 0.9998837423846397, 0.8431039249266333, 0.9994264830462525, 0.9473714223276608, 0.9998837423846397, 0.9891817452104279, 0.9996828965823179, 0.00035219129353964264, 0.9092466006594615, 0.9996282985802916, 8.925984756465322e-05, 0.9990692414584673, 0.9653959260287865, 8.593802206029477e-05, 0.00011668312036814094, 0.00014847172853154483, 0.00012658216188396145, 0.0001442165932706208, 0.9920435983384437, 0.35836806196949783, 0.000129970020312278, 0.8995087252164602, 0.0001355167244033516, 0.9969166304616321, 0.9573040455565679, 0.9927146872239154, 0.00015052396670221424, 0.9998837423846397, 0.00010473743277947397, 0.26348081414813146, 0.9990215332377335, 0.9942937258127225, 0.9987870476009764, 0.00013364207526689293, 0.3335184383288162, 0.997883269104538, 0.00019074899145091054, 0.0001735107809474731, 0.9997103726857567, 0.00013487113185781644, 0.18540738247809813, 0.996882044243228, 0.9973128315949501, 9.86368241437987e-05, 0.9264453560931943, 8.925984756465322e-05, 0.4307673714285168, 0.00014967490737515443, 0.9993150424692666, 0.00015151533312950143, 0.0002452339304876343, 9.691201315926492e-05, 0.24394462127055153, 0.00015151533312950143, 0.33924778504295816, 0.9996828965823179, 0.00013615017190342937, 0.9998837423846397, 0.9995073335985499, 0.9996761344458595, 0.9998735434462112, 0.00016134347356294072, 0.9998837423846397, 0.9998837423846397, 0.9992678020932919, 0.00035219129353964264, 0.7238965611072872, 0.18760760586941333, 0.9999096547282988, 0.9999268697564094, 0.999905894469594, 0.9994053796444189, 0.30189826691925253, 0.9996761344458595, 0.9997122530975403, 0.9892269421457419, 0.9990595520826252, 0.007126178140243106, 0.7678506554313045, 0.9977247389710155, 0.9999096547282988, 0.9541232133986769, 0.9919733628931873, 0.9985626847628267, 0.9998910506174983, 0.998877744825767, 0.9925420610925183, 0.3079647207372113, 0.9984639763399962, 0.31041056827836977, 0.0003030946270267483, 0.9918268653600526, 0.988758894886612, 0.0061401779545284165, 0.9927276801581199, 8.966687729423584e-05, 0.9996828965823179, 0.9996784712482033, 0.00035219129353964264, 0.3589938567498285, 0.0001535012829031235, 0.9992107769585946, 0.9998837423846397, 0.999905894469594, 0.006881091576279511, 0.999611156961625, 0.5052076133832082, 0.9897363039834086, 0.9921308824890308, 6.43864482342962e-05, 0.0001306908820128211, 0.9998837423846397, 0.6902012986784128, 0.005862234329944208, 0.2987993811468678, 0.00016498550225774034, 0.9998910506174983, 0.998758393979024, 0.0001434908012337498, 0.0001144113030410952, 0.999905894469594, 0.9653026038966845, 0.9998399404915767, 0.6195826809546777, 0.9993868886325258, 0.0001589307182692447, 0.010969584253158023, 0.18675401050365065, 0.9558619066330563, 0.9998832554840715, 0.99741132978918, 0.9989620739872076, 0.9987575701735351, 0.5009566703820649, 0.9984596352613586, 0.9996763701451702, 0.9940873426122039, 0.9996828965823179, 0.9336477038608771, 0.998954784713541, 0.9998832554840715, 0.8156059882527666, 0.42065076351697706, 0.2648356069087882, 0.9989974336831365, 9.77252700608985e-05, 0.9996884490988924, 0.9998837423846397, 0.9998837423846397, 0.9917356969439712, 0.005154235175783567, 0.9989620739872076, 0.9992379689043154, 0.9998837423846397, 0.9999096547282988, 0.00014477727648379865, 0.9998837423846397, 0.9866711034754847, 0.9996207215216234, 0.25945335645742884, 0.8995735736550756, 0.9998832554840715, 0.00015151533312950143, 0.999611156961625, 0.9965703624225463, 0.00011837235119794629, 0.0003030946270267483, 0.9998854100009966, 0.9996761344458595, 0.6261378170630912, 0.8608013327093956, 0.7351351804024977, 0.9998854100009966, 8.135015384841945e-05, 0.999905894469594, 0.999905894469594, 0.3006609623936193, 7.745017238890062e-05, 0.0001543562560825421, 0.9990595520826252, 0.9998837423846397, 0.00016316732669299696, 0.00012099294184442302, 0.9986773154331673, 0.9998837423846397, 0.34241575602122715, 0.992507430934953, 0.00012257052723717264, 0.0001338147775629836, 0.2906922734816599, 0.9947589798033419, 0.42564795323566795, 0.999611156961625, 0.7834488185704446, 0.32303747526629834, 0.9998837423846397, 0.9998837423846397, 0.9996761344458595, 0.9992361791243506, 0.0001589307182692447, 0.9998837423846397, 0.9894123886744095, 0.000140035442995986, 8.379307847963799e-05, 0.9998837423846397, 0.9974060260585386, 0.9917049559701238, 0.9998837423846397, 0.9133346403864625, 0.9987575701735351, 0.0003030946270267483, 0.0001176145603466874, 0.21152515488346102, 0.9960678583828758, 0.9990943433366186, 0.999905894469594, 0.999905894469594, 0.9998837423846397, 0.00010959448512185174, 0.9997156561627168, 0.00015846634965139883, 0.004099977802843737, 0.9996828965823179, 0.9938660446327576, 0.999905894469594, 0.9918268653600526, 0.0001329194453627358, 0.9989007633325252, 7.219039324362957e-05, 0.999611156961625, 0.9998865364025179, 0.8408961101677905, 0.00011609186438528934, 0.9958816034401117, 0.9998343108930393, 0.9998832554840715, 0.9998837423846397, 0.9745626683714635, 0.9918939507882453, 0.0001735107809474731, 0.20921810749825498, 0.44174979942008336, 0.9998837423846397, 0.0001589307182692447, 0.00014967490737515443, 0.9999171540317326, 0.00018049772194836332, 0.44581723214958807, 0.9918717869859602, 0.1778844197516547, 0.9992373621840459, 0.002685089219135842, 0.9981163284606346, 0.00015151533312950143, 0.9998837423846397, 9.863102208187813e-05, 0.34456713478329365, 0.9983197469677132, 0.9996761344458595, 0.4564735532814859, 0.9998837423846397, 0.9911340714679547, 0.9998837423846397, 0.0001589307182692447, 0.9998837423846397, 0.9993150424692666, 0.1610602157793937, 0.5025934633777245, 0.9998837423846397, 0.9982673285285959, 0.9989318630290399, 0.00014614452351796353, 0.9983902821774042, 0.00012067155979129708, 0.999905894469594, 0.9998837423846397, 0.9996682776772532, 0.9915879290046007, 0.9996828965823179, 0.9966835818566382, 0.9965849037117032, 0.9944688548453036, 0.9966204555003373, 0.9998837423846397, 0.9998837423846397, 8.120997007917664e-05, 0.999905894469594, 0.00013989982265739923, 0.20921810749825498, 0.9976579881340498, 0.5229341748415917, 0.44659927142065425, 0.9942769597224729, 8.512739447159824e-05, 0.6886260862477691, 0.9997013869916725, 0.9992859015900313, 0.9998399404915767, 9.596123166308937e-05, 0.00011556137924681707, 0.00011760819328236451, 0.9935667163327709, 9.84554802406729e-05, 0.9993330367866458, 0.00014967490737515443, 0.00013746213730295436, 0.6670101876869509, 0.9998928155544562, 0.2824441224602859, 0.31774516980783746, 0.9859267056085519, 0.9998837423846397, 0.9999268697564094, 0.005738555282226928, 0.9998837423846397, 0.9985872675619512, 0.9267516018083507, 0.9996786899063498, 0.00013837659643025577, 0.6046060810664481, 0.9998837423846397, 0.9992686072009279, 0.0001426913179768187, 0.980947595177557, 0.9989318630290399, 0.9996828965823179, 0.00017879743974576263, 0.9854033317020888, 0.00015770480692099383, 0.7689439392662369, 0.9971124134426822, 0.9998837423846397, 0.9935315368705223, 0.00015151533312950143, 0.7735876900589277, 0.999905894469594, 0.997300202338062, 0.9980677677135043, 0.9822265383420488, 0.00015151533312950143, 0.00013615017190342937, 0.9998837423846397, 0.00011071186084556763, 9.596123166308937e-05, 0.999611156961625, 0.00010824196038576055, 0.00014244230375251208, 0.8702707257798676, 0.9998399404915767, 0.9991643873508264, 0.0001183853473502862, 0.9998837423846397, 0.856546342742865, 0.9982970962847909, 0.17286968343111278, 0.9992981669439214, 0.999611156961625, 0.00014276316103492697, 0.9988485574108188, 0.9867887943795125, 0.9989974336831365, 0.980947595177557, 0.00011897104486074405, 0.00014006374578014603, 7.819042768162283e-05, 0.9989591501029611, 0.9998837423846397, 0.999905894469594, 0.9693684280578425, 0.22274256434038303, 9.29432011530321e-05, 0.9945172819516318, 0.27931184495512196, 0.00010179189032650734, 0.922679225972565, 7.791171989653727e-05, 0.8608013327093956, 0.00015151533312950143, 0.9986606716440974, 0.999905894469594, 0.00017346502222551443, 0.9998837423846397, 0.9998837423846397, 0.9920683980882349, 0.00015151533312950143, 0.00013867893776782896, 0.4371749375294844, 0.9999137089777405, 0.00013615017190342937, 0.9992981669439214, 0.9998853498558521, 0.16534784367624059, 0.999905894469594, 0.9961336986723583, 0.9990392476356381, 9.542745863046232e-05, 0.9996828965823179, 0.808441294956085, 0.9902874540551104, 0.9996805919320815, 0.0001797477205714774, 0.9846203607882822, 0.9998837423846397, 0.9996805919320815, 0.9980677677135043, 0.9532092686213315, 0.0001589307182692447, 0.009158306438684136, 0.989064788509682, 0.9998837423846397, 0.9998837423846397, 0.006881091576279511, 0.9999171540317326, 0.9884974078451553, 0.00014853566849646328, 0.9996057308606813, 0.999905894469594, 0.941206687641379, 0.974815368688983, 0.21065282079708422, 0.8764569324126685, 0.0001543562560825421, 0.9989620739872076, 0.00013298251159470225, 0.6887225755742116, 0.5263126545496319, 0.9998837423846397, 0.9853554903830607, 0.49455330154143173, 0.00014380365321072422, 0.8371622574768974, 0.3943633395068936, 0.6497021589021001, 0.9990595520826252, 0.9998832554840715, 0.9981559142461662, 0.0001475412506064381, 0.9979084694589615, 0.5450480722664706, 0.9996828965823179, 0.9792109639465378, 0.00018049772194836332, 0.9847498044271866, 0.9911441778684935, 0.9984038154536198, 0.00010455377187655189, 0.14815716688639136, 0.2814150425052661, 0.9643564246604017, 0.00035219129353964264, 0.9990595520826252, 0.9998837423846397, 0.00011765909882719928, 0.9999171540317326, 0.00011039751457047962, 0.9998837423846397, 0.9987128326753352, 0.3199536118020318, 0.00013615017190342937, 0.8687333995538038, 0.00011996203625801824, 0.9992882901729992, 0.0001370108226642508, 0.9998837423846397, 0.23305767856362747, 0.9992683086368817, 0.9098039572403024, 0.36716269855224376, 0.00035219129353964264, 0.999905894469594, 0.2906922734816599, 0.45051302785585473, 0.0003030946270267483, 0.13670404471773404, 0.9990007312753483, 0.49023522031301764, 0.002335600904770351, 0.00017320364233789967, 9.459490609593557e-05, 0.20748602472103547, 0.9998837423846397, 8.653410011806654e-05, 0.00013557475740503516, 0.9992935656514875, 0.9998910506174983, 0.9933346765866753, 0.17691131692973522, 9.675392018661172e-05, 8.547251199536606e-05, 0.9998837423846397, 0.00014178773882101564, 0.12740962096194344, 0.9939711379441145, 0.9998837423846397, 0.9928998500540819, 0.39966042697403514, 0.716121936916762, 0.9999096547282988, 0.9972203323048928, 0.00010851032893630211, 0.9943097385142208, 0.00014244230375251208, 0.30841453873129854, 0.7717778812234714, 0.00013046801235549137, 0.9618342295628289, 0.00014803528549618355, 0.00010356395171532195, 0.999611156961625, 0.9983197469677132, 0.9996786899063498, 8.909992718922463e-05, 0.5136895409287865, 0.9996496109352513, 0.9998899512983547, 0.9998837423846397, 8.512442390871985e-05, 0.00035219129353964264, 0.8314559852495133, 0.0003030946270267483, 0.00011168501932548274, 0.9998865364025179, 0.00015088896205349127, 0.00015151533312950143, 0.9998837423846397, 0.99851976308245, 0.9994199893054433, 0.9987660141289605, 0.9998865364025179, 8.512442390871985e-05, 0.9998837423846397, 0.00011849590301689022, 0.1620383506150125, 0.9998837423846397, 0.00011172515012575134, 0.9998837423846397, 0.9996786899063498, 0.9996809895778542, 0.9977453885406865, 0.9118373998406295, 0.9989045724072195, 0.44354946435348336, 0.5543985922506933, 0.9991498919877754, 0.00015527298036178971, 0.909462391459502, 0.004906561172739952, 0.999905894469594, 0.9998837423846397, 0.0001589307182692447, 0.00011343202508052394, 0.9971953732613827, 0.9998837423846397, 0.9996828965823179, 0.4766579771876283, 0.9814100747430825, 0.00015151533312950143, 0.9644532081801027, 0.00011765909882719928, 0.9992058459486379, 0.9965742380486524, 0.16576724446676697, 0.0001336767097737167, 0.9912039802287077, 0.9925236716847383, 0.9998837423846397, 0.5136895409287865, 0.0001707095898514906, 0.9996761344458595, 0.2100953020796624, 0.9998399404915767, 0.9772606287676342, 0.9998837423846397, 0.9990215332377335, 0.999905894469594, 0.9984596352613586, 0.00010651446118011308, 0.9966835818566382, 9.29432011530321e-05, 0.9985326557286768, 0.999231406703255, 0.9966835818566382, 0.9989066866048658, 0.999905894469594, 0.9992986302683249, 0.9983902821774042, 0.32346862813097027, 0.998897860120431, 0.9954621292555212, 0.0001051225073374217, 0.9906714743214249, 0.0001482396480409586, 0.9998914116782995, 0.9987194985278505, 0.9998910506174983, 0.17393057590947666, 0.589065673682908, 0.9985748457509376, 0.9998720308995397, 0.9998854100009966, 8.816769408149905e-05, 6.615003283664743e-05, 0.9998837423846397, 0.7499536411941877, 0.999905894469594, 0.5860884028075559, 0.9594954002069139, 0.9988983156630298, 0.9917356969439712, 0.00010216918350622595, 0.9966835818566382, 0.0001547122994349711, 0.9998837423846397, 0.9998853498558521, 0.00017320364233789967, 0.9846933006176631, 0.9974646104083285, 0.9989785591318632, 0.6210670338561227, 0.0002039841962170149, 0.23505169429768902, 9.99543225157526e-05, 0.9897727553528841, 0.9992734061502734, 0.00012103167937444024, 0.9993150424692666, 0.00015151533312950143, 0.7635902116332984, 0.4967438096560948, 0.0003030946270267483, 0.9998837423846397, 0.9406094901574714, 0.9302276200946656, 0.9984152038176385, 0.9459510012693108, 0.9994240091443302, 0.5367104684125651, 0.9994757355145081, 0.00014967490737515443, 0.6031984866976184, 0.9998837423846397, 0.8646717320306991, 0.9999171540317326, 0.9974735104148483, 0.26937975461758257, 0.00013024637202293298, 9.277412281887627e-05, 0.9988579884187627, 0.9951420882731894, 0.9967217323242572, 0.9988652545750402, 0.9908955738744758, 0.9993202018218705, 0.21564751806382274, 0.9767359989952059, 0.9928377303964985, 0.00011648905792121732, 0.00016502391246864254, 0.6577480461504376, 7.745017238890062e-05, 9.043567186112572e-05, 0.25588722034440625, 0.99884037766372, 0.00015151533312950143, 0.9998832554840715, 0.9999268697564094, 0.9996828965823179, 0.30238738961320794, 0.8988313649959828, 0.9919733628931873, 0.9968696712194298, 0.9998231362415761, 0.000157527752825506, 0.00015151533312950143, 0.9998837423846397, 0.999905894469594, 0.9780024705931962, 0.9998837423846397, 0.9996786899063498, 0.9998910506174983, 0.9975341807325153, 0.004814647436346917, 0.9996828965823179, 0.9998914116782995, 0.998870094397896, 0.9920239485069651, 0.9996784712482033, 7.775621414730821e-05, 0.999905894469594, 0.999905894469594, 0.9913374104965734, 0.00014525239591547695, 0.9952268799253479, 0.9996786899063498, 0.7681507037567811, 0.9994394576718788, 0.9976184693379526, 0.999905894469594, 0.5161280392045267, 0.9614448388934442, 0.24740179067263443, 0.27137342738135417, 0.36716269855224376, 0.9998837423846397, 0.00011217298884037466, 0.00013557475740503516, 0.9461296986052862, 0.999905894469594, 0.9993150424692666, 0.0001589307182692447, 0.9992734061502734, 8.120997007917664e-05, 0.0001426913179768187, 0.992061930461313, 0.9991498919877754, 0.9998837423846397, 0.9994240091443302, 0.9988764794204166, 0.34845367693855883, 0.7643182582411088, 0.9876199499868702, 0.00012658216188396145, 0.9998837423846397, 0.983987884005044, 0.9988323751754415, 7.600916132894414e-05, 7.315554944188137e-05, 0.005088883612919659, 0.9998837423846397, 0.6562667188444398, 0.9996828965823179, 0.9998837423846397, 0.19657993898496348, 0.9985970636741068, 0.0001004772934206381, 0.9998837423846397, 0.00014759663594999446, 0.986005293268868, 0.0003030946270267483, 0.8358778726517364, 0.7678506554313045, 0.9080701132529309, 0.9429589789775463, 0.00012787208543745102, 0.9998837423846397, 0.29013241524203176, 0.8900752498957177, 0.4949543034521838, 0.00015151533312950143, 0.9998837423846397, 0.7652801092045933, 0.9998399404915767, 0.9998837423846397, 0.9998837423846397, 0.9600697920858478, 0.9996761344458595, 9.29432011530321e-05, 0.9847571923359675, 0.0001500215582282088, 0.1900867123922975, 0.9984137184736106, 0.9980136120651754, 0.00015151533312950143, 0.7979198032774263, 0.9923409888488292, 0.6957572396545334, 0.9936265582803407, 0.9998837423846397, 0.9948315371018684, 0.999905894469594, 0.00015151533312950143, 0.9998837423846397, 0.9990215332377335, 0.7151000720666532, 0.9943300077447017, 0.9958542023602704, 0.9987575701735351, 0.9992981669439214, 0.00018049772194836332, 0.00015151533312950143, 0.0001589307182692447, 0.9998837423846397, 0.3814204864996037, 0.9987444513363728, 0.9998837423846397, 0.00014157277285567967, 0.9863885110445259, 0.9926722451746912, 0.00012999254257682602, 0.9998375485958133, 0.9974374398347606, 0.00015151533312950143, 0.00011446103818174146, 0.7635902116332984, 0.9996828965823179, 0.9917356969439712, 0.0001547122994349711, 0.9990215332377335, 0.00011554723865902362, 0.00012664843694041187, 0.9199373344573242, 0.9998837423846397, 0.9990011934447535, 0.9932862543662256, 0.00035219129353964264, 0.9999096547282988, 0.999905894469594, 0.00013615017190342937, 0.9459510012693108, 0.00016316732669299696, 0.9998837423846397, 0.0005992546291541577, 0.9978773008311819, 0.00012798573956492756, 0.9989381633703236, 0.6537214198925981, 0.9996828965823179, 0.9990215332377335, 7.494650717540074e-05, 9.84554802406729e-05, 0.9993150424692666, 0.000129248973183035, 0.9987575701735351, 0.9942750867179317, 0.9990893013212722, 0.9995073335985499, 0.9998837423846397, 0.27075842954203777, 0.9998837423846397, 0.99543243316717, 0.00015144492058241486, 0.9992555055813908, 0.9947504924963071, 0.9917356969439712, 0.9740108558543835, 0.993000973189785, 0.9998837423846397, 0.2830610925683996, 0.0001707095898514906, 0.923370647418607, 0.9999171540317326, 0.9917356969439712, 0.9999137089777405, 8.73200066266441e-05, 0.9998899512983547, 0.7885869643350767, 0.27749462719890616, 9.691201315926492e-05, 0.09512951148783404, 0.758843012438308, 0.9998837423846397, 0.9998837423846397, 0.0001177181754226286, 8.689399775516596e-05, 0.47316761705441135, 0.9998837423846397, 0.9993830346268678, 0.00010162984524844392, 0.9827971959465219, 0.00015311491451759114, 0.9998837423846397, 0.33611151537054307, 0.9998837423846397, 7.5664235492532e-05, 0.9776803844995302, 0.9975853625343416, 0.0028933544130712633, 0.9753864125751412, 0.999882156940931, 0.44519395352022384, 0.002292973575083467, 0.34697249469175445, 0.9967218488196387, 0.00011347007790547295, 0.00010216918350622595, 0.9996282985802916, 0.00012354205156738573, 0.9988214446606967, 0.9974248241673236, 0.8000816034238908, 0.00011197677950509319, 0.9327099779754644, 0.9998837423846397, 0.9992830642966247, 0.9917675091388182, 0.9998889593229126, 0.992061930461313, 0.9992734061502734, 0.9998837423846397, 0.9996784712482033, 0.9996809895778542, 0.00040668169726411823, 0.9988591035950506, 0.999338630255691, 0.9990893013212722, 0.0001753944800659037, 0.9977829631689054, 0.9996786899063498, 0.9919733628931873, 0.4876038570752588, 0.9996805919320815, 0.9986556353323541, 0.8658369659000537, 0.999905894469594, 0.8755560761723347, 9.84554802406729e-05, 0.000125370465015921, 0.9906873401704303, 0.9996828965823179, 0.00014967490737515443, 0.9986974863065965, 0.00011208426648911312, 7.819042768162283e-05, 0.4967438096560948, 0.9999171540317326, 0.2575422410301257, 0.999905894469594, 0.9922988517415217, 0.9335238461126562, 0.003467257872372575, 0.9998837423846397, 0.99987256460796, 0.8094128393426108, 0.992097202421998, 0.989786932201965, 0.9998837423846397, 0.9998837423846397, 0.999905894469594, 0.9998854100009966, 0.9953837182470366, 0.00022338676391784365, 0.20921810749825498, 0.38558851591138543, 0.9996429958120586, 0.361968090637195, 0.00014833074929334244, 0.9992189357955311, 0.9998837423846397, 0.9998343108930393, 0.00015770480692099383, 0.3872463022709639, 0.9998837423846397, 0.35364282660410107, 0.20285144341539654, 0.4649950394467996, 0.00010462308283966622, 0.9987870476009764, 0.998593811043303, 0.9990215332377335, 0.9990215332377335, 0.20213729619939955, 0.2226264062648856, 0.9989620739872076, 0.999415047403554, 0.9984057871905219, 0.9996057308606813, 9.277412281887627e-05, 0.9935981115461949, 0.9996763701451702, 0.9980243711448026, 0.9998976521337084, 0.5450722156576319, 0.9998837423846397, 0.0001704027275183923, 0.00015537533115405033, 0.00016011981356131428, 0.5349028980892908, 0.00010455377187655189, 0.9996308969129098, 0.9998837423846397, 0.9996763701451702, 0.0037289622916108415, 0.9947589798033419, 0.9971978891543241, 0.45051302785585473, 0.0001589307182692447, 0.9189292377708742, 0.00014435206534546533, 0.9071871820760952, 0.005482296943104746, 0.9998837423846397, 0.9984180805418861, 0.9992126649216707, 0.9998837423846397, 0.999611156961625, 0.992061930461313, 0.2920529989175556, 0.99896226000624, 0.9461296986052862, 0.00013615017190342937, 0.9993124479561025, 0.0001547122994349711, 0.7251881141130914, 0.00011105262684770212, 0.9987518859473056, 0.00035219129353964264, 0.7421006450531394, 0.00013557475740503516, 0.9543946935570203, 0.9987575701735351, 0.0067751479662449205, 0.0001413258795926673, 0.32617278218732904, 0.999611156961625, 0.0001105994029463034, 0.00010824196038576055, 0.999905894469594, 0.3169443583543841, 0.973646840948313, 0.00014001198343446618, 0.999905894469594, 0.9996828965823179, 0.00013615017190342937, 0.999905894469594, 0.7140898243019875, 0.9992373621840459, 0.999905894469594, 0.9998688087824612, 0.00018201611643501683, 0.25588722034440625, 0.9998253526136163, 0.000129248973183035, 0.00013418979518185192, 0.9998837423846397, 0.9918268653600526, 0.660782697352156, 0.9998837423846397, 0.7735876900589277, 0.993258786172812, 0.9990590606810609, 0.9908795195480589, 0.9492594216340791, 8.512442390871985e-05, 0.00014556443123628037, 0.3559346126997507, 0.997296309810202, 0.9883512133405182, 0.9429589789775463, 0.9998399404915767, 0.23505169429768902, 0.40474174912252525, 0.2894070920146187, 0.9998837423846397, 0.9996786899063498, 0.9998837423846397, 0.00015151533312950143, 0.9996809895778542, 0.9873784297882237, 0.9988178806576669, 0.00014506426444752812, 0.9998837423846397, 8.593802206029477e-05, 0.9859358868906415, 0.9996786899063498, 0.9996828965823179, 0.4766579771876283, 0.9943029794608176, 0.9995058392587134, 0.7238965611072872, 0.9998837423846397, 0.9998865364025179, 0.9990215332377335, 0.4241576616812984, 0.9999171540317326, 0.9998837423846397, 0.00012202139865220661, 0.9779748353133019, 0.9999096547282988, 0.00013746213730295436, 7.236992012975201e-05, 0.9992981669439214, 0.9990590606810609, 0.1441780977284248, 0.9972392173346464, 9.43524453353346e-05, 0.9146264801822113, 0.9998837423846397, 0.9998914116782995, 0.9986188965561137, 0.9998089600395964, 0.9998837423846397, 0.34920416530230597, 0.00011115934920948254, 0.998408930459571, 0.000173523800349474, 0.9998910506174983, 0.0001413258795926673, 0.00013487702190372795, 0.9998837423846397, 0.9998837423846397, 0.9998472218072099, 0.999874632276183, 0.4649950394467996, 0.0001589307182692447, 0.9904392771064104], \"drift\": 0}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "test = pickle.loads(rc1.get(allkey[10]))\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    rows.append(row.to_list())\n",
    "\n",
    "data = {\n",
    "  \"id\": \"123\",\n",
    "  \"rows\": rows,\n",
    "  \"columns\": test.columns.to_list()\n",
    "}\n",
    "\n",
    "import requests\n",
    "response = requests.post('http://14.225.205.204:80/phase-2/prob-1/predict', json=data)\n",
    "#response = requests.post('http://192.168.88.113:8000/phase-2/prob-1/predict', json=data)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aiocache import Cache\n",
    "from aiocache.serializers import PickleSerializer\n",
    "\n",
    "cacherequest = Cache(Cache.REDIS, endpoint=\"localhost\", port=6379, db=1, serializer=PickleSerializer())\n",
    "await cacherequest.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
